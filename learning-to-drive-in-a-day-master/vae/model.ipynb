{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2018 Roma Sokolkov\n",
    "# Copyright (c) 2018 hardmaru\n",
    "# MIT License\n",
    "\n",
    "'''\n",
    "VAE models.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json        #一个库，\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    return data/255.0\n",
    "\n",
    "\n",
    "def denormalize(data):\n",
    "    return data * 255.0\n",
    "\n",
    "\n",
    "class ConvVAE(object):\n",
    "  def __init__(self, z_size=512, batch_size=100, learning_rate=0.0001, kl_tolerance=0.5, is_training=True, reuse=False, gpu_mode=True):\n",
    "    self.z_size = z_size\n",
    "    self.batch_size = batch_size\n",
    "    self.learning_rate = learning_rate\n",
    "    self.is_training = is_training\n",
    "    self.kl_tolerance = kl_tolerance\n",
    "    self.reuse = reuse\n",
    "    with tf.variable_scope('conv_vae', reuse=self.reuse):\n",
    "      if not gpu_mode:\n",
    "        with tf.device('/cpu:0'):\n",
    "          tf.logging.info('Model using cpu.')\n",
    "          self._build_graph()\n",
    "      else:\n",
    "        tf.logging.info('Model using gpu.')\n",
    "        self._build_graph()\n",
    "    self._init_session()\n",
    "\n",
    "  def _build_graph(self):\n",
    "    self.g = tf.Graph()\n",
    "    with self.g.as_default():\n",
    "\n",
    "      self.x = tf.placeholder(tf.float32, shape=[None, 80, 160, 3])\n",
    "\n",
    "      # Encoder\n",
    "      h = tf.layers.conv2d(self.x, 32, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv1\")\n",
    "      h = tf.layers.conv2d(h, 64, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv2\")\n",
    "      h = tf.layers.conv2d(h, 128, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv3\")\n",
    "      h = tf.layers.conv2d(h, 256, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv4\")\n",
    "      h = tf.reshape(h, [-1, 3*8*256])\n",
    "\n",
    "      # VAE\n",
    "      self.mu = tf.layers.dense(h, self.z_size, name=\"enc_fc_mu\")\n",
    "      self.logvar = tf.layers.dense(h, self.z_size, name=\"enc_fc_log_var\")\n",
    "      self.sigma = tf.exp(self.logvar / 2.0)\n",
    "      self.epsilon = tf.random_normal([self.batch_size, self.z_size])\n",
    "      self.z = self.mu + self.sigma * self.epsilon\n",
    "\n",
    "      # Decoder\n",
    "      h = tf.layers.dense(self.z, 3*8*256, name=\"dec_fc\")\n",
    "      h = tf.reshape(h, [-1, 3, 8, 256])\n",
    "      h = tf.layers.conv2d_transpose(h, 128, 4, strides=2, activation=tf.nn.relu, name=\"dec_deconv1\")\n",
    "      h = tf.layers.conv2d_transpose(h, 64, 4, strides=2, activation=tf.nn.relu, name=\"dec_deconv2\")\n",
    "      h = tf.layers.conv2d_transpose(h, 32, 5, strides=2, activation=tf.nn.relu, name=\"dec_deconv3\")\n",
    "      self.y = tf.layers.conv2d_transpose(h, 3, 4, strides=2, activation=tf.nn.sigmoid, name=\"dec_deconv4\")\n",
    "\n",
    "      # train ops\n",
    "      if self.is_training:\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        eps = 1e-6 # avoid taking log of zero\n",
    "\n",
    "        # reconstruction loss\n",
    "        self.r_loss = tf.reduce_sum(\n",
    "          tf.square(self.x - self.y),\n",
    "          reduction_indices = [1,2,3]\n",
    "        )\n",
    "        self.r_loss = tf.reduce_mean(self.r_loss)\n",
    "\n",
    "        # augmented kl loss per dim\n",
    "        self.kl_loss = - 0.5 * tf.reduce_sum(\n",
    "          (1 + self.logvar - tf.square(self.mu) - tf.exp(self.logvar)),\n",
    "          reduction_indices = 1\n",
    "        )\n",
    "        self.kl_loss = tf.maximum(self.kl_loss, self.kl_tolerance * self.z_size)\n",
    "        self.kl_loss = tf.reduce_mean(self.kl_loss)\n",
    "\n",
    "        self.loss = self.r_loss + self.kl_loss\n",
    "\n",
    "        # training\n",
    "        self.lr = tf.Variable(self.learning_rate, trainable=False)\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        grads = self.optimizer.compute_gradients(self.loss) # can potentially clip gradients here.\n",
    "\n",
    "        self.train_op = self.optimizer.apply_gradients(\n",
    "          grads, global_step=self.global_step, name='train_step')\n",
    "\n",
    "      # initialize vars\n",
    "      self.init = tf.global_variables_initializer()\n",
    "\n",
    "  def _init_session(self):\n",
    "    \"\"\"Launch TensorFlow session and initialize variables\"\"\"\n",
    "    self.sess = tf.Session(graph=self.g)\n",
    "    self.sess.run(self.init)\n",
    "\n",
    "  def close_sess(self):\n",
    "    \"\"\" Close TensorFlow session \"\"\"\n",
    "    self.sess.close()\n",
    "\n",
    "  def encode(self, x):\n",
    "    return self.sess.run(self.z, feed_dict={self.x: x})\n",
    "\n",
    "  def decode(self, z):\n",
    "    return self.sess.run(self.y, feed_dict={self.z: z})\n",
    "\n",
    "  def get_model_params(self):\n",
    "    # get trainable params.\n",
    "    model_names = []\n",
    "    model_params = []\n",
    "    model_shapes = []\n",
    "    with self.g.as_default():\n",
    "      t_vars = tf.trainable_variables()\n",
    "      for var in t_vars:\n",
    "        param_name = var.name\n",
    "        p = self.sess.run(var)\n",
    "        model_names.append(param_name)\n",
    "        params = np.round(p*10000).astype(np.int).tolist()\n",
    "        model_params.append(params)\n",
    "        model_shapes.append(p.shape)\n",
    "    return model_params, model_shapes, model_names\n",
    "\n",
    "  def get_random_model_params(self, stdev=0.5):\n",
    "    # get random params.\n",
    "    _, mshape, _ = self.get_model_params()\n",
    "    rparam = []\n",
    "    for s in mshape:\n",
    "      #rparam.append(np.random.randn(*s)*stdev)\n",
    "      rparam.append(np.random.standard_cauchy(s)*stdev) # spice things up!\n",
    "    return rparam\n",
    "\n",
    "  def set_model_params(self, params):\n",
    "    with self.g.as_default():\n",
    "      t_vars = tf.trainable_variables()\n",
    "      idx = 0\n",
    "      for var in t_vars:\n",
    "        pshape = self.sess.run(var).shape\n",
    "        p = np.array(params[idx])\n",
    "        assert pshape == p.shape, \"inconsistent shape\"\n",
    "        assign_op = var.assign(p.astype(np.float)/10000.)\n",
    "        self.sess.run(assign_op)\n",
    "        idx += 1\n",
    "\n",
    "  def load_json(self, jsonfile='vae.json'):\n",
    "    with open(jsonfile, 'r') as f:\n",
    "      params = json.load(f)\n",
    "    self.set_model_params(params)\n",
    "\n",
    "  def save_json(self, jsonfile='vae.json'):\n",
    "    model_params, model_shapes, model_names = self.get_model_params()\n",
    "    qparams = []\n",
    "    for p in model_params:\n",
    "      qparams.append(p)\n",
    "    with open(jsonfile, 'wt') as outfile:\n",
    "      json.dump(qparams, outfile, sort_keys=True, indent=0, separators=(',', ': '))\n",
    "\n",
    "  def set_random_params(self, stdev=0.5):\n",
    "    rparam = self.get_random_model_params(stdev)\n",
    "    self.set_model_params(rparam)\n",
    "\n",
    "  def save_model(self, model_save_path):\n",
    "    sess = self.sess\n",
    "    with self.g.as_default():\n",
    "      saver = tf.train.Saver(tf.global_variables())\n",
    "    checkpoint_path = os.path.join(model_save_path, 'vae')\n",
    "    tf.logging.info('saving model %s.', checkpoint_path)\n",
    "    saver.save(sess, checkpoint_path, 0) # just keep one\n",
    "\n",
    "  def load_checkpoint(self, checkpoint_path):\n",
    "    sess = self.sess\n",
    "    with self.g.as_default():\n",
    "      saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "    print('loading model', ckpt.model_checkpoint_path)\n",
    "    tf.logging.info('Loading model %s.', ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
